{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main: \n",
    "\n",
    "This notebook, as long as it's run from the hdfs repo of one of our users (as set in the beginning of the notebook) should be enough to obtain the desired planner as all dataframes necessary are stored on our repos. Otherwise, you are welcome to first run the other notebooks and run from your repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%configure\n",
    "{\"pyFiles\": [\"/user/gottraux/dijkstra_algorithms.py\"],\n",
    " \"conf\": {\n",
    "    \"spark.app.name\": \"dslab-group_final\"\n",
    "}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and helper functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import time\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "MAX_TRIP_DURATION = 2 #duration in hour \n",
    "\n",
    "days_dict = {0: 'monday', 1: 'tuesday', 2: 'wednesday', 3: 'thursday', 4: 'friday'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set which home will be used to load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "import os\n",
    "import pandas as pd\n",
    "username = 'liseli'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%send_to_spark -i username -t str -n username"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load graph data: \n",
    "\n",
    "Load information to create our network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = spark.read.format('orc').load('/data/sbb/timetables/orc/trips/000000_0')\n",
    "calendar = spark.read.format('orc').load('/data/sbb/timetables/orc/calendar/000000_0')\n",
    "\n",
    "nodes_df = spark.read.orc(\"/user/{}/nodes.orc\".format(username))\n",
    "edges_df = spark.read.orc(\"/user/{}/edges_with_mean_and_std_sec.orc\".format(username))\n",
    "\n",
    "nodes = nodes_df.rdd.map(lambda r: (r[0], {'name': r['stop_name'],\n",
    "                                              'lat': r['stop_lat'],\n",
    "                                              'lon': r['stop_lon']})).collect()\n",
    "# reverse edges by:\n",
    "edges_df = edges_df.withColumnRenamed('stop_id', 'temp')\\\n",
    "                    .withColumnRenamed('next_stop', 'stop_id').withColumnRenamed('temp', 'next_stop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load walking edges from pickle file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "walking_times = pd.read_pickle('walking_edges.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%send_to_spark -i walking_times -t df -m 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse edges for walking edges also:\n",
    "walking_times = (walking_times.withColumnRenamed('source', 'temp').withColumnRenamed('target', 'source').withColumnRenamed('temp', 'target'))\n",
    "\n",
    "edges_walking = walking_times.toPandas()\n",
    "edges_walking['attrs'] = edges_walking.apply(lambda x: {'time': -1, 'duration': x['walk_duration']}, axis=1)\n",
    "edges_walking = list(edges_walking[['source', 'target', 'attrs']].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for the creation of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_trips(*day_ids):\n",
    "    \"\"\"\n",
    "    day_trips: gives the trip_ids that operate on certain days\n",
    "    input: a variable number of day ids\n",
    "    output:s spark dataframe with trip_ids\n",
    "    \n",
    "    \"\"\"\n",
    "    days = [days_dict[day_id] for day_id in day_ids]\n",
    "    where_clause = \" and \".join(days)\n",
    "\n",
    "    day_services = calendar.where(where_clause).select('service_id')\n",
    "    return day_services.join(trips, on='service_id').select('trip_id')\n",
    "\n",
    "def create_edges_for_trip(edges_df, day_id, arrival_time):\n",
    "    \"\"\"\n",
    "    create_edges_for_trip: constructs edges (and thus trips) that exist in a window of two hours before a given input time\n",
    "    @input:\n",
    "    - edges_df: df from which we construct the edges\n",
    "    - day_id: id of week-day (e.g. wednesday is day id 2, see dictionnary above)\n",
    "    - hour, minute: time at which we want to arrive somewhere (e.g. 11:30)\n",
    "    @output: data frame of selected edges\n",
    "    \"\"\"\n",
    "    #select only the trips that occur on that day:\n",
    "    edges_df= edges_df.join(day_trips(day_id), on='trip_id')\n",
    "    \n",
    "    min_dep_time = arrival_time - 60*MAX_TRIP_DURATION\n",
    "    \n",
    "    #keep only those in a window of two hours:\n",
    "    edges_df = edges_df.filter((col('departure_time') > min_dep_time) & \n",
    "                                            (col('arrival_time') <= arrival_time))\n",
    "    \n",
    "    edges = edges_df.rdd.map(lambda r: (r['stop_id'], r['next_stop'], {'duration': r['trip_duration'],\n",
    "                                                                       'time': float(r['departure_time']),\n",
    "                                                                       'trip_id': r['trip_id'],\n",
    "                                                                       'mean': r['mean'],\n",
    "                                                                       'std': r['std'],\n",
    "                                                                       'transport': r['train_type'], \n",
    "                                                                      'p_90':r['p_90'],\n",
    "                                                                       'p_91':r['p_91'],\n",
    "                                                                       'p_92':r['p_92'],\n",
    "                                                                       'p_93':r['p_93'],\n",
    "                                                                       'p_94':r['p_94'],\n",
    "                                                                       'p_95':r['p_95'],\n",
    "                                                                       'p_96':r['p_96'],\n",
    "                                                                       'p_97':r['p_97'],\n",
    "                                                                       'p_98':r['p_98'],\n",
    "                                                                       'p_99':r['p_99']})).collect()\n",
    "    \n",
    "    return edges + edges_walking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dijkstra's algorithm for shortest path:\n",
    "\n",
    "See `README.md`for description of algorith. \n",
    "\n",
    "#### Validation for Dijkstra:\n",
    "##### Feasible paths: \n",
    "`is_path_valid` is a function that looks through a path to see if it is valid. \n",
    "So it looks for:\n",
    "- missed connections\n",
    "- transfer time of less than 2 minutes between two transports\n",
    "\n",
    "##### Validate a path:\n",
    "\n",
    "`validate_path_`:for a given path from Dijkstra, this function samples delays for transfers where we go from a transport -> walk or transport -> transport. \n",
    "- For transport 1 -> transport 2: the delay of transport 1 will be added to its trip duration\n",
    "- For transport -> walk: the delay of transport will be added to the departure time of walk \n",
    "\n",
    "After modifying these values, the function checks if the path is still feasible. This operation is repeated a certain number of times and if the percentage of feasible paths is higher or equal to the wished confidence, the path is validated. \n",
    "\n",
    "This function is called in Dijkstra. As we wish a path validated for a certain confidence, if Dijkstra's path is not validated, Dijkstra will increase its confidence till it gets a valid path or none.\n",
    "\n",
    "To not use too much space in this notebook, they are in a dedicated file (with all functions related to Dijsktra). Default to /user/gottraux/dijkstra_algorithms.py on the hdfs filesystem (loaded in the spark context at the top of the notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To load (or reload) into hdfs, need to update cell at the top of the notebook and restart kernel\n",
    "\n",
    "hdfs dfs -rm /user/${JUPYTERHUB_USER}/dijkstra_algorithms.py 2>/dev/null\n",
    "hdfs dfs -copyFromLocal notebooks/dijkstra_algorithms.py /user/${JUPYTERHUB_USER}/\n",
    "\"\"\"\n",
    "from dijkstra_algorithms import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "import ipywidgets as widgets\n",
    "import fuzzy_pandas as fpd\n",
    "import time\n",
    "\n",
    "def search_station(station):\n",
    "    search = pd.DataFrame([station], columns=['station'])\n",
    "    matches = fpd.fuzzy_merge(search, stations_name, left_on='station', right_on='stop_name',\n",
    "                              ignore_case=True, ignore_nonalpha=True, ignore_nonlatin=True, ignore_order_words=True,\n",
    "                              keep='match', threshold=0.8, method='jaro')\n",
    "    return matches['stop_name'].to_list()\n",
    "\n",
    "def search_station_departure(sender):\n",
    "    phrase = depart_station.value\n",
    "    depart_proposals.options = search_station(phrase)\n",
    "    \n",
    "def search_station_arrival(sender):\n",
    "    phrase = arrive_station.value\n",
    "    arrive_proposals.options = search_station(phrase)\n",
    "    \n",
    "no_station_selected = \"None selected\"\n",
    "\n",
    "def select_station_departure(sender):\n",
    "    if(sender['name'] == 'label'):\n",
    "        if(sender['new'] == None):\n",
    "            selected_depart_station.value = no_station_selected\n",
    "        else:\n",
    "            selected_depart_station.value = sender['new']\n",
    "            \n",
    "def select_station_arrival(sender):\n",
    "    if(sender['name'] == 'label'):\n",
    "        if(sender['new'] == None):\n",
    "            selected_arrival_station.value = no_station_selected\n",
    "        else:\n",
    "            selected_arrival_station.value = sender['new']\n",
    "            \n",
    "def find_route_button(button):\n",
    "    # Parse arguments\n",
    "    depart_station_str = selected_depart_station.value\n",
    "    if depart_station_str == no_station_selected:\n",
    "        report_error(\"No departure station selected\")\n",
    "        return\n",
    "    \n",
    "    arrive_station_str = selected_arrival_station.value\n",
    "    if arrive_station_str == no_station_selected:\n",
    "        report_error(\"No arrival station selected\")\n",
    "        return\n",
    "    \n",
    "    date = date_picker.value\n",
    "    if(date == None):\n",
    "        report_error(\"No date selected\")\n",
    "        return\n",
    "    \n",
    "    if(date.weekday() > 4):\n",
    "        report_error(\"Date is a weekend day, please select a week day\")\n",
    "        return\n",
    "    \n",
    "    hour_str = hour_picker.value\n",
    "    \n",
    "    if hour_str == None or hour_str == \"\":\n",
    "        report_error(\"No hour selected\")\n",
    "        return\n",
    "    \n",
    "    hour_str = hour_str.split(':')\n",
    "    hour = -1\n",
    "    minute = -1\n",
    "    \n",
    "    try:\n",
    "        if(len(hour_str) != 2):\n",
    "            raise Error\n",
    "        hour = int(hour_str[0])\n",
    "        minute = int(hour_str[1])        \n",
    "    except:\n",
    "        report_error(\"Invalid hour format, use HH:MM\")\n",
    "        return\n",
    "    \n",
    "    if(hour not in range(8,21)):\n",
    "        report_error(\"Invalid hour, valid range: [8,20]\")\n",
    "        return\n",
    "            \n",
    "    if(minute not in range(0,60)):\n",
    "        report_error(\"Invalid minute, valid range: [0,59]\")\n",
    "        return\n",
    "        \n",
    "    confidence = confidence_picker.value\n",
    "        \n",
    "    report_error(None)\n",
    "    \n",
    "    \n",
    "    # Show progress bar\n",
    "    results.children = []\n",
    "    progress_bar.layout = widgets.Layout(display='block')\n",
    "    \n",
    "    # Send variables to spark\n",
    "    # Convert to str for 'send_to_spark'\n",
    "    date_str = date.strftime(\"%Y-%m-%d\")\n",
    "    hour_str = str(hour)\n",
    "    minute_str = str(minute)\n",
    "    confidence_str = str(confidence)\n",
    "    get_ipython().push(['depart_station_str', 'arrive_station_str', 'date_str', 'hour_str', 'minute_str', 'confidence_str'])\n",
    "    get_ipython().run_cell_magic('send_to_spark', ' -i depart_station_str -t str -n depart_station_str', ' ')\n",
    "    get_ipython().run_cell_magic('send_to_spark', ' -i arrive_station_str -t str -n arrive_station_str', ' ')\n",
    "    get_ipython().run_cell_magic('send_to_spark', ' -i date_str -t str -n date_str', ' ')\n",
    "    get_ipython().run_cell_magic('send_to_spark', ' -i hour_str -t str -n hour_str', ' ')\n",
    "    get_ipython().run_cell_magic('send_to_spark', ' -i minute_str -t str -n minute_str', ' ')\n",
    "    get_ipython().run_cell_magic('send_to_spark', ' -i confidence_str -t str -n confidence_str', ' ')\n",
    "\n",
    "    # Run algorithm\n",
    "    get_ipython().run_cell_magic('spark', '', \"\"\"\n",
    "    result = get_result_path(depart_station_str, arrive_station_str, date_str, hour_str, minute_str, confidence_str)\n",
    "    \"\"\")\n",
    "    \n",
    "    # Retrive results from spark\n",
    "    get_ipython().run_cell_magic('spark', '-o result', ' ')\n",
    "    \n",
    "    # Display path\n",
    "    progress_bar.layout = widgets.Layout(display='none')\n",
    "    display_path(result)\n",
    "    \n",
    "def display_path(path):\n",
    "    stops = []\n",
    "    \n",
    "    for index, row in path.iterrows():\n",
    "        start = row['from']\n",
    "        end = row['to']\n",
    "        duration = row['duration']\n",
    "        departure_time = row['departure_time'].strftime(\"%H:%M\")\n",
    "        walk = row['walk']\n",
    "        transport = row['transport']\n",
    "        \n",
    "        message =  f\"<p style='font-size: 20px; padding-bottom:10px;'>{transport}, {start} <b>&rarr;</b> {end}, {duration:.1f} minutes</p>\" if walk\\\n",
    "                    else f\"<p style='font-size: 20px; padding-bottom:10px;'>{transport}, {departure_time}: {start} <b>&rarr;</b> {end}, {duration:.1f} minutes</p>\"\n",
    "        \n",
    "        stops.append(widgets.HTML(value=message))\n",
    "        \n",
    "    results.children = stops\n",
    "    \n",
    "def report_error(error_message):\n",
    "    if error_message == None:\n",
    "        error.value = \"\"\n",
    "    else:\n",
    "        error.value = \"<b style='color:red;'>Error: \" + error_message  + \"</b>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_result_path(start_str, end_str, date_str, hour_str, minute_str, confidence_str):\n",
    "    day_id = time.strptime(date_str, \"%Y-%m-%d\").tm_wday\n",
    "    \n",
    "    arrival_hour = int(hour_str)\n",
    "    arrival_minute = int(minute_str)\n",
    "    arrival_time = arrival_hour*60+arrival_minute\n",
    "    departure_time = arrival_time - MAX_TRIP_DURATION*60\n",
    "    \n",
    "    confidence = int(confidence_str) / 100.0\n",
    "    \n",
    "    print(\"Parsed arguments\")\n",
    "    \n",
    "    source = nodes_df.where(col('stop_name') == start_str).take(1)[0][0][:7]\n",
    "    target = nodes_df.where(col('stop_name') == end_str).take(1)[0][0][:7]\n",
    "    \n",
    "    print(\"Found ids\")\n",
    "    \n",
    "    # Put in function\n",
    "    edges = create_edges_for_trip(edges_df, day_id, arrival_time)\n",
    "    graph = nx.MultiDiGraph()\n",
    "    graph.add_nodes_from(nodes)\n",
    "    graph.add_edges_from(edges)\n",
    "    \n",
    "    print(\"Created graph\")\n",
    "\n",
    "    old_number_of_nodes = graph.number_of_nodes()\n",
    "    # Remove unreachable nodes\n",
    "    dists, paths = normal_dijkstra(graph, '8503000')\n",
    "    not_reachable = set(graph.nodes) - set(dists.keys())\n",
    "    _ = graph.remove_nodes_from(list(not_reachable))\n",
    "    print('{} nodes removed'.format(old_number_of_nodes - graph.number_of_nodes()))\n",
    "\n",
    "    # Temp for problem of name's encoding\n",
    "    import unicodedata\n",
    "    nodes_data = graph.nodes(data=True)\n",
    "    for n in graph.nodes:\n",
    "        nodes_data[n]['name'] = unicodedata.normalize('NFKD', nodes_data[n]['name']).encode('ascii','ignore')\n",
    "    \n",
    "    \n",
    "    print(\"Ran on cluster !\")\n",
    "    print(\"From {} to {} on {} at {}:{} for confidence {}\".format(start_str, end_str, date_str, hour_str, minute_str, confidence_str))\n",
    "    \n",
    "    path = dijkstra_reversed(graph, source, arrival_time, last_target=target, confidence=confidence)\n",
    "    return spark.createDataFrame(path)\n",
    "\n",
    "stations_name = nodes_df.select('stop_name').distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -o stations_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "style = {'description_width': 'initial'}\n",
    "\n",
    "# Search station\n",
    "depart_station = widgets.Text(description = 'Search departure station',\n",
    "                              layout=widgets.Layout(width='40%'),\n",
    "                              style=style)\n",
    "depart_station.observe(search_station_departure)\n",
    "arrive_station = widgets.Text(description = 'Search arrival station',\n",
    "                              layout=widgets.Layout(width='40%'),\n",
    "                              style=style)\n",
    "arrive_station.observe(search_station_arrival)\n",
    "\n",
    "\n",
    "# Proposals\n",
    "depart_proposals = widgets.Select(description = 'Found stations',\n",
    "                                  layout=widgets.Layout(width='40%', height='200px'),\n",
    "                                  style=style)\n",
    "depart_proposals.observe(select_station_departure)\n",
    "arrive_proposals = widgets.Select(description = 'Found stations',\n",
    "                                  layout=widgets.Layout(width='40%', height='200px'),\n",
    "                                  style=style)\n",
    "arrive_proposals.observe(select_station_arrival)\n",
    "\n",
    "\n",
    "# Stations\n",
    "selected_depart_station = widgets.Label(value = no_station_selected, style=style)\n",
    "selected_box_depart_station = widgets.HBox([widgets.Label(value = \"Selected depart station: \", style=style),\n",
    "                                             selected_depart_station], layout=widgets.Layout(width='40%'))\n",
    "selected_arrival_station = widgets.Label(value = no_station_selected, style=style)\n",
    "selected_box_arrival_station = widgets.HBox([widgets.Label(value = \"Selected arrival station: \", style=style),\n",
    "                                             selected_arrival_station], layout=widgets.Layout(width='40%'))\n",
    "\n",
    "\n",
    "\n",
    "# Options\n",
    "date_picker = widgets.DatePicker(\n",
    "                    description='Pick a Date',\n",
    "                    disabled=False,\n",
    "                    layout=widgets.Layout(width='20%')\n",
    "                )\n",
    "hour_picker = widgets.Text(description = 'Arrival time',\n",
    "                            placeholder='HH:MM',\n",
    "                            layout=widgets.Layout(width='20%'),\n",
    "                            style=style\n",
    "                          )\n",
    "confidence_picker = widgets.IntSlider(\n",
    "            value=95,\n",
    "            min=90,\n",
    "            max=99,\n",
    "            step=1,\n",
    "            description='Confidence:',\n",
    "            disabled=False,\n",
    "            continuous_update=False,\n",
    "            orientation='horizontal',\n",
    "            readout=True,\n",
    "            readout_format='d',\n",
    "            layout=widgets.Layout(width='25%'),\n",
    "            style=style\n",
    "        )\n",
    "search_button = widgets.Button(\n",
    "            description='Find route',\n",
    "            disabled=False,\n",
    "            button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "            tooltip='Find route',\n",
    "            icon='check', # (FontAwesome names without the `fa-` prefix)\n",
    "            layout=widgets.Layout(width='15%')\n",
    "        )\n",
    "search_button.on_click(find_route_button)\n",
    "\n",
    "\n",
    "# Error\n",
    "error = widgets.HTML(value=\"\")\n",
    "\n",
    "\n",
    "padding = widgets.HTML(value=\"\", layout=widgets.Layout(height='50px'))\n",
    "\n",
    "# Progress bar\n",
    "progress_bar = widgets.HTML(value=\"Finding best route...\", layout=widgets.Layout(display='none'))\n",
    "\n",
    "# Result\n",
    "results = widgets.VBox([])\n",
    "\n",
    "stations = widgets.HBox([depart_station, arrive_station])\n",
    "proposals = widgets.HBox([depart_proposals, arrive_proposals])\n",
    "selected_stations = widgets.HBox([selected_box_depart_station, selected_box_arrival_station])\n",
    "options = widgets.HBox([date_picker, hour_picker, confidence_picker, search_button])\n",
    "layout = widgets.VBox([stations, proposals, selected_stations, options, error, padding, progress_bar, results])\n",
    "\n",
    "layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: for visualisation most stations start with `ZÃ¼rich, ...`. Try with that if you can't find your station."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the algorithm without the visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose an arrival time to create a graph: (all edges will leave at most 2 hours before this arrival time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_id, arrival_hour, arrival_minute = 4, 12, 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = create_edges_for_trip(edges_df, day_id, arrival_hour*60+arrival_minute)\n",
    "\n",
    "graph = nx.MultiDiGraph()\n",
    "graph.add_nodes_from(nodes)\n",
    "graph.add_edges_from(edges)\n",
    "\n",
    "old_number_of_nodes = graph.number_of_nodes()\n",
    "# Remove unreachable nodes (e.g. those that have a trip outside of 15km to reach them)\n",
    "dists, paths = normal_dijkstra(graph, '8503000')\n",
    "not_reachable = set(graph.nodes) - set(dists.keys())\n",
    "_ = graph.remove_nodes_from(list(not_reachable))\n",
    "\n",
    "# Temp for problem of name's encoding:\n",
    "import unicodedata\n",
    "nodes_data = graph.nodes(data=True)\n",
    "for n in graph.nodes:\n",
    "    nodes_data[n]['name'] = unicodedata.normalize('NFKD', nodes_data[n]['name']).encode('ascii','ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Dijkstra's reversed algorithm: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tao's example: \n",
    "\"\"\"\n",
    "Route 1: HB -> Auszelg\n",
    "20.TA.26-9-A-j19-1.2.H: 8503000:0:41/42 at 12:07:00 ~ 8503310:0:3 at 12:17:00\n",
    "Walking: 8503310:0:3 ~ 8590620\n",
    "168.TA.26-12-A-j19-1.2.H: 8590620 at 12:23:00 ~ 8591049 at 12:29:00\n",
    "\"\"\"\n",
    "best_path1 = dijkstra_reversed(graph, '8503000', arrival_hour*60+arrival_minute, last_target='8591049', confidence=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another example, with and without confidence: \n",
    "\"\"\"\n",
    "Route 2:\n",
    "Zurich, Triemli (8503610) to Zurich Altstetten, Bahnhof N (8591057)\n",
    "\"\"\"\n",
    "# From Triemli to Altstetten bahnhof:\n",
    "print('Without confidence ->')\n",
    "best_path1 = dijkstra_reversed(graph, '8503610', arrival_hour*60+arrival_minute, last_target='8591057')\n",
    "print('')\n",
    "print('With confidence of 98% ->')\n",
    "best_path1 = dijkstra_reversed(graph, '8503610', arrival_hour*60+arrival_minute, last_target='8591057', confidence=0.98)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
