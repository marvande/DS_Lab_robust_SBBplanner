{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create walking edges:\n",
    "\n",
    "This notebook computes the time it takes to walk between stations that are under 500m from each-other. It will then be saved as a pickle file. The time to walk is extracted from the ```transfers``` file present on the hdfs filesystem and otherwise is computed as 2min + 1min per 50m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%configure\n",
    "{\"conf\": {\n",
    "    \"spark.app.name\": \"dslab-group_final\"\n",
    "}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = spark.read.format('orc').load('/data/sbb/timetables/orc/stops/000000_0')\n",
    "transfers = spark.read.format('orc').load('/data/sbb/timetables/orc/transfers/000000_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import distance as geo_distance\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the distance between all stops in order to select those under 500m distance (as the crow flies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zurich_distance(x, y):\n",
    "    \"\"\"zurich_distance: returns the distance of a station to Zurich HB\n",
    "    @input: (lat,lon) of a station\n",
    "    @output: distance in km to Zurich HB\n",
    "    \"\"\"\n",
    "    # position calculated in creat_edge_and_nodes.ipynb\n",
    "    zurich_pos = (47.3781762039461, 8.54019357578468)\n",
    "    return geo_distance(zurich_pos, (x,y)).km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@udf(\"float\")\n",
    "def compute_distance(x1, y1, x2, y2):\n",
    "    \"\"\"\n",
    "    Compute distance takes as input two pairs of latitude and longitude coming\n",
    "    from two different stops and compute the distance between those two stops in meters \n",
    "    \"\"\"\n",
    "    return geo_distance((x1, y1), (x2,y2)).m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use latitude and longitude to filter stops that are only within 15 km of Zurich HB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_distance = stops.rdd.map(lambda x: (x['stop_id'], zurich_distance(x['stop_lat'], x['stop_lon'])))\n",
    "stops_distance = spark.createDataFrame(stops_distance.map(lambda r: Row(stop_id=r[0], \n",
    "                                                                        zurich_distance=r[1])))\n",
    "stops_distance = stops_distance.filter(col('zurich_distance') <= 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create DataFrame containing all possible pairs of stops with their latitude and longitude and then compute the distance between old pairs of stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_pos = stops.join(stops_distance, 'stop_id').select(col('stop_id'), \n",
    "                                                         col('stop_lat'), col('stop_lon'))\n",
    "stops_pos = stops_pos.select(col('stop_id').alias('stop_id_1'), \n",
    "                             col('stop_lat').alias('stop_lat_1'), \n",
    "                             col('stop_lon').alias('stop_lon_1'))\n",
    "stops_pos = stops_pos.crossJoin(stops_pos.select(col('stop_id_1').alias('stop_id_2'), \n",
    "                                                 col('stop_lat_1').alias('stop_lat_2'), col('stop_lon_1').alias('stop_lon_2')))\n",
    "stops_pos = stops_pos.where(col('stop_id_1') != col('stop_id_2'))\n",
    "stops_pos_dist = stops_pos.withColumn('distance', \n",
    "                                      compute_distance(col('stop_lat_1'), \n",
    "                                                       col('stop_lon_1'), \n",
    "                                                       col('stop_lat_2'), \n",
    "                                                       col('stop_lon_2')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep only pairs for which the distance is less than 500 meters and compute the duration using a speed of 50 meters per minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walking_edges = stops_pos_dist.select(col('stop_id_1').alias('source'), col('stop_id_2').alias('target'), \n",
    "                                      col('distance'))\\\n",
    "                                        .where(col('distance') <= 500)\\\n",
    "                                        .withColumn('duration', col('distance')/50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfers = transfers.select('from_stop_id', 'to_stop_id', 'min_transfer_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -o transfers -n 30000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%spark -o walking_edges -n 30000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is available information for a transfer between stations, we add it to `walking_edges`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%local\n",
    "merged = transfers.merge(walking_edges, \n",
    "                         left_on=['from_stop_id', 'to_stop_id'], \n",
    "                         right_on=['source', 'target'], how='right')\n",
    "\n",
    "mask_transfers = merged.to_stop_id.notnull() & merged.from_stop_id.notnull()\n",
    "\n",
    "merged.loc[mask_transfers, 'walk_duration'] = merged.loc[mask_transfers, 'min_transfer_time'] / 60\n",
    "merged.loc[~mask_transfers, 'walk_duration'] = merged.loc[~mask_transfers, 'duration'] + 2\n",
    "merged[['source', 'target', 'walk_duration']].to_pickle('walking_edges.pickle')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
